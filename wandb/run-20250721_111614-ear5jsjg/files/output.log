Using LocalLogger is deprecated. The constructor API will change
[36m(pid=4803)[0m /root/miniconda3/envs/venv/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=4803)[0m No module named 'vllm._version'
[36m(pid=4803)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=5009)[0m /root/miniconda3/envs/venv/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=5009)[0m No module named 'vllm._version'
[36m(pid=5009)[0m   from vllm.version import __version__ as VLLM_VERSION
[36m(pid=5007)[0m /root/miniconda3/envs/venv/lib/python3.10/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
[36m(pid=5007)[0m No module named 'vllm._version'
[36m(pid=5007)[0m   from vllm.version import __version__ as VLLM_VERSION
Error executing job with overrides: ['algorithm.adv_estimator=grpo', "data.train_files=['/fs-computility/mabasic/fanyuchen/Rethink-Search_tmp/verl_temp/ZeroSearch_dataset/train.parquet']", "data.val_files=['/fs-computility/mabasic/fanyuchen/Rethink-Search_tmp/verl_temp/ZeroSearch_dataset/test.parquet']", 'data.train_batch_size=256', 'data.max_prompt_length=1024', 'data.max_response_length=4096', 'actor_rollout_ref.model.path=/fs-computility/mabasic/shared/models/Llama-3.2-3B-Instruct', 'actor_rollout_ref.actor.optim.lr=1e-6', 'actor_rollout_ref.model.use_remove_padding=True', 'actor_rollout_ref.actor.ppo_mini_batch_size=256', 'actor_rollout_ref.actor.ppo_micro_batch_size=64', 'actor_rollout_ref.actor.use_kl_loss=True', 'actor_rollout_ref.actor.kl_loss_coef=0.001', 'actor_rollout_ref.actor.kl_loss_type=low_var_kl', 'actor_rollout_ref.actor.entropy_coeff=0', 'actor_rollout_ref.model.enable_gradient_checkpointing=True', 'actor_rollout_ref.actor.fsdp_config.param_offload=True', 'actor_rollout_ref.actor.optim.lr_warmup_steps_ratio=0.02', 'actor_rollout_ref.actor.fsdp_config.optimizer_offload=True', 'actor_rollout_ref.rollout.log_prob_micro_batch_size=128', 'actor_rollout_ref.rollout.tensor_model_parallel_size=1', 'actor_rollout_ref.rollout.name=vllm', 'actor_rollout_ref.rollout.gpu_memory_utilization=0.7', 'actor_rollout_ref.rollout.n_agent=5', 'actor_rollout_ref.ref.fsdp_config.param_offload=True', 'trainer.val_before_train=False', 'trainer.critic_warmup=0', 'trainer.logger=[console,wandb]', 'trainer.project_name=Rethink Search Scaling', 'trainer.experiment_name=llama_3.1_8b_inst_grpo_init', 'trainer.n_gpus_per_node=4', 'trainer.val_before_train=False', 'trainer.nnodes=1', 'trainer.save_freq=10000', 'trainer.test_freq=16', 'trainer.total_epochs=5']
Traceback (most recent call last):
  File "/fs-computility/mabasic/fanyuchen/Rethink-Search/ZeroSearch/verl/trainer/main_ppo.py", line 156, in main
    main_task(config)
  File "/fs-computility/mabasic/fanyuchen/Rethink-Search/ZeroSearch/verl/trainer/main_ppo.py", line 228, in main_task
    trainer.init_workers()
  File "/fs-computility/mabasic/fanyuchen/Rethink-Search/ZeroSearch/verl/trainer/ppo/ray_trainer.py", line 657, in init_workers
    self.ref_policy_wg.init_model()
  File "/fs-computility/mabasic/fanyuchen/Rethink-Search/ZeroSearch/verl/single_controller/ray/base.py", line 42, in func
    output = ray.get(output)
  File "/root/miniconda3/envs/venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 21, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/root/miniconda3/envs/venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/root/miniconda3/envs/venv/lib/python3.10/site-packages/ray/_private/worker.py", line 2771, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/root/miniconda3/envs/venv/lib/python3.10/site-packages/ray/_private/worker.py", line 919, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ModuleNotFoundError): [36mray::WorkerDict.ref_init_model()[39m (pid=5009, ip=172.30.50.152, actor_id=ab75cb4143da1b944440fd9701000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x7f83bf8055a0>)
  File "/fs-computility/mabasic/fanyuchen/Rethink-Search/ZeroSearch/verl/single_controller/ray/base.py", line 399, in func
    return getattr(self.worker_dict[key], name)(*args, **kwargs)
  File "/fs-computility/mabasic/fanyuchen/Rethink-Search/ZeroSearch/verl/single_controller/base/decorator.py", line 404, in inner
    return func(*args, **kwargs)
  File "/fs-computility/mabasic/fanyuchen/Rethink-Search/ZeroSearch/verl/workers/fsdp_workers.py", line 286, in init_model
    from verl.workers.actor import DataParallelPPOActor
  File "/fs-computility/mabasic/fanyuchen/Rethink-Search/ZeroSearch/verl/workers/actor/__init__.py", line 16, in <module>
    from .dp_actor import DataParallelPPOActor
  File "/fs-computility/mabasic/fanyuchen/Rethink-Search/ZeroSearch/verl/workers/actor/dp_actor.py", line 34, in <module>
    from flash_attn.bert_padding import pad_input, unpad_input, rearrange, index_first_axis
ModuleNotFoundError: No module named 'flash_attn'

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
